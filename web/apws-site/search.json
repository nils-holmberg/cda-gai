[
  {
    "objectID": "apws-module-1.html",
    "href": "apws-module-1.html",
    "title": "1: All programs need data?",
    "section": "",
    "text": "# Empty code cell with Python comment preceded by hash sign \"# \"\n\n\nGenerate a simple Python program\nPlanned focus: Line-by-line palindrome checker\n\nKey topics / activities: Strings, slicing, input/file I/O, stepwise refinement (hardcoded → input() → file)\nExample / mini-project: Read a text file and print whether each line is a palindrome\n\n\n# TODO: Implement: Generate a simple Python program for Day 1\n# Suggested starting hints from schedule:\n# Title: Line-by-line palindrome checker\n# Key topics / activities: Strings, slicing, input/file I/O, stepwise refinement (hardcoded → input() → file)\n# Example / Mini-project: Read a text file and print whether each line is a palindrome\n\n# Write your code here...\n\ndef palindrome_test(some_string):\n    \n    # normalize input string, lowercase\n    char_list_norm = [i for i in some_string.lower()]\n    \n    # reverse normalized string\n    char_list_back = [i for i in reversed(char_list_norm)]\n    \n    # step through character list\n    for i,x in enumerate(char_list_norm):\n        \n        # for each step, compare with reversed list\n        if char_list_norm[i] == char_list_back[i]:\n            \n            # if lists are same, palindrome so far\n            pali_flag = 0\n            \n            # go to next list items\n            continue\n        \n        # list element are different\n        else:\n            \n            # flag palindrome test failed\n            pali_flag = 1\n            \n            # exit list comparison loop\n            break\n    \n    # check the result of string palindrome test\n    if pali_flag &gt; 0:\n        \n        # output message to user\n        print(some_string, \"palindrome false\")\n    \n    # if list comparison completed without flag\n    else:\n        \n        # output message to user\n        print(some_string, \"palindrome true\")\n\n# run function on input strings\npalindrome_test(\"anna\")\n\n#\npalindrome_test(\"annaa\")\n\nanna palindrome true\nannaa palindrome false\n\n\n\n\nSolve problem in your own work\nPlanned focus: Personalized emails from TSV\n\nKey topics / activities: File I/O (TSV), f-strings/templates, loops\nExample / mini-project: Read a name list TSV and generate short personalized mail messages\n\n\n# TODO: Implement: Solve problem in your own work for Day 1\n# Suggested starting hints from schedule:\n# Title: Personalized emails from TSV\n# Key topics / activities: File I/O (TSV), f-strings/templates, loops\n# Example / Mini-project: Read a name list TSV and generate short personalized mail messages\n\n# Write your code here...\n\n\n\nPerform data science using GenAI\nPlanned focus: Load real-world data into pandas\n\nKey topics / activities: Pandas read_csv/read_table/read_excel, parsing unstructured text\nExample / mini-project: Load Excel/TSV/text into a single DataFrame and preview/clean columns\n\n\n# TODO: Implement: Perform data science using GenAI for Day 1\n# Suggested starting hints from schedule:\n# Title: Load real-world data into pandas\n# Key topics / activities: Pandas `read_csv`/`read_table`/`read_excel`, parsing unstructured text\n# Example / Mini-project: Load Excel/TSV/text into a single DataFrame and preview/clean columns\n\n# Write your code here...",
    "crumbs": [
      "About",
      "1: All programs need data?"
    ]
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Resources",
    "section": "",
    "text": "Weder, Krainer, and Karmasin (2021)\n\n\n\n\n\n\n\nLakshmanan, Görner, and Gillard (2021)\n\n\n\n\n\n\n\nVasilev (2019)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDey (2018)\n\n\n\n\n\n\n\nLakshmanan, Görner, and Gillard (2021)\n\n\n\n\n\n\n\nVasilev (2019)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVasiliev (2020)\n\n\n\n\n\n\n\nTunstall, Von Werra, and Wolf (2022)\n\n\n\n\n\n\n\nSzeliski (2010)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMcKinney (2022)\n\n\n\n\n\n\n\n(some-test?)\n\n\n\n\n\n\n\n(some-test?)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNeuendorf (2017)\n\n\n\n\n\n\n\nKedia and Rasu (2020)\n\n\n\n\n\n\n\nSzeliski (2010)",
    "crumbs": [
      "About",
      "Overview"
    ]
  },
  {
    "objectID": "resources.html#literature",
    "href": "resources.html#literature",
    "title": "Resources",
    "section": "",
    "text": "Weder, Krainer, and Karmasin (2021)\n\n\n\n\n\n\n\nLakshmanan, Görner, and Gillard (2021)\n\n\n\n\n\n\n\nVasilev (2019)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDey (2018)\n\n\n\n\n\n\n\nLakshmanan, Görner, and Gillard (2021)\n\n\n\n\n\n\n\nVasilev (2019)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVasiliev (2020)\n\n\n\n\n\n\n\nTunstall, Von Werra, and Wolf (2022)\n\n\n\n\n\n\n\nSzeliski (2010)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMcKinney (2022)\n\n\n\n\n\n\n\n(some-test?)\n\n\n\n\n\n\n\n(some-test?)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNeuendorf (2017)\n\n\n\n\n\n\n\nKedia and Rasu (2020)\n\n\n\n\n\n\n\nSzeliski (2010)",
    "crumbs": [
      "About",
      "Overview"
    ]
  },
  {
    "objectID": "resources.html#websites-and-apps",
    "href": "resources.html#websites-and-apps",
    "title": "Resources",
    "section": "websites and apps",
    "text": "websites and apps\n\nhttps://www.python.org/downloads/\nhttps://wiki.python.org/moin/BeginnersGuide\nhttps://www.anaconda.com/products/individual\nhttps://code.visualstudio.com/download\nhttps://github.com/jupyterlab/jupyterlab_app#download\nhttps://trinket.io/home",
    "crumbs": [
      "About",
      "Overview"
    ]
  },
  {
    "objectID": "resources.html#online-articles",
    "href": "resources.html#online-articles",
    "title": "Resources",
    "section": "online articles",
    "text": "online articles\n\nsome text here Kedia and Rasu (2020)",
    "crumbs": [
      "About",
      "Overview"
    ]
  },
  {
    "objectID": "apws-module-4.html",
    "href": "apws-module-4.html",
    "title": "4: Humans need data summary",
    "section": "",
    "text": "# Empty code cell with Python comment preceded by hash sign \"# \"\n\n\nGenerate a simple Python program\nPlanned focus: Date differences with holidays & weeks\n\nKey topics / activities: datetime arithmetic, Swedish holidays count, full-weeks calc\nExample / mini-project: Input two dates; output days between, #Swedish holidays, #full weeks\n\n\n# TODO: Implement: Generate a simple Python program for Day 4\n# Suggested starting hints from schedule:\n# Title: Date differences with holidays & weeks\n# Key topics / activities: `datetime` arithmetic, Swedish holidays count, full-weeks calc\n# Example / Mini-project: Input two dates; output days between, #Swedish holidays, #full weeks\n\n# Write your code here...\n\n\n\nSolve problem in your own work\nPlanned focus: Group summaries with SEM\n\nKey topics / activities: Groupby aggregations: count, mean, std, SEM\nExample / mini-project: From TSV with 3-level categorical + numeric, compute grouped stats (count/mean/std/SEM)\n\n\n# TODO: Implement: Solve problem in your own work for Day 4\n# Suggested starting hints from schedule:\n# Title: Group summaries with SEM\n# Key topics / activities: Groupby aggregations: count, mean, std, SEM\n# Example / Mini-project: From TSV with 3-level categorical + numeric, compute grouped stats (count/mean/std/SEM)\n\n# Write your code here...\n\n\n\nPerform data science using GenAI\nPlanned focus: Summary table by factor on penguins\n\nKey topics / activities: Groupby on categorical IV, numeric DV; formatted table\nExample / mini-project: Aggregate a numeric DV by a categorical IV and render a neat summary table\n\n\n# TODO: Implement: Perform data science using GenAI for Day 4\n# Suggested starting hints from schedule:\n# Title: Summary table by factor on penguins\n# Key topics / activities: Groupby on categorical IV, numeric DV; formatted table\n# Example / Mini-project: Aggregate a numeric DV by a categorical IV and render a neat summary table\n\n# Write your code here...",
    "crumbs": [
      "About",
      "4: Humans need data summary"
    ]
  },
  {
    "objectID": "apws-module-3.html",
    "href": "apws-module-3.html",
    "title": "3: Data transformations!!",
    "section": "",
    "text": "# Empty code cell with Python comment preceded by hash sign \"# \"\n\n\nGenerate a simple Python program\nPlanned focus: Normalize a list to 0–1 and compare\n\nKey topics / activities: Min–max scaling, lists → DataFrame, two-column output\nExample / mini-project: Create a two-column DataFrame: original vs normalized values\n\n\n# TODO: Implement: Generate a simple Python program for Day 3\n# Suggested starting hints from schedule:\n# Title: Normalize a list to 0–1 and compare\n# Key topics / activities: Min–max scaling, lists → DataFrame, two-column output\n# Example / Mini-project: Create a two-column DataFrame: original vs normalized values\n\n# Write your code here...\n\n\n\nSolve problem in your own work\nPlanned focus: Anonymize & categorize respondents\n\nKey topics / activities: Regex for names, age binning into 3 groups\nExample / mini-project: Read TSV (first,last,age,preference), anonymize IDs, add 3 age categories\n\n\n# TODO: Implement: Solve problem in your own work for Day 3\n# Suggested starting hints from schedule:\n# Title: Anonymize & categorize respondents\n# Key topics / activities: Regex for names, age binning into 3 groups\n# Example / Mini-project: Read TSV (first,last,age,preference), anonymize IDs, add 3 age categories\n\n# Write your code here...\n\n\n\nPerform data science using GenAI\nPlanned focus: Median split & missing-value handling on penguins\n\nKey topics / activities: Recode numeric → categorical (median), drop NAs\nExample / mini-project: Recode a numeric variable by median split; remove missing values\n\n\n# TODO: Implement: Perform data science using GenAI for Day 3\n# Suggested starting hints from schedule:\n# Title: Median split & missing-value handling on penguins\n# Key topics / activities: Recode numeric → categorical (median), drop NAs\n# Example / Mini-project: Recode a numeric variable by median split; remove missing values\n\n# Write your code here...",
    "crumbs": [
      "About",
      "3: Data transformations!!"
    ]
  },
  {
    "objectID": "apws-module-2.html",
    "href": "apws-module-2.html",
    "title": "2: Understand your dataset",
    "section": "",
    "text": "# Empty code cell with Python comment preceded by hash sign \"# \"\n\n\nGenerate a simple Python program\nPlanned focus: Line-by-line prime number tester\n\nKey topics / activities: Loops, modulo, input/file I/O, simple edge cases\nExample / mini-project: Test numbers from hardcoded/input/file and label prime/non-prime\n\n\n# TODO: Implement: Generate a simple Python program for Day 2\n# Suggested starting hints from schedule:\n# Title: Line-by-line prime number tester\n# Key topics / activities: Loops, modulo, input/file I/O, simple edge cases\n# Example / Mini-project: Test numbers from hardcoded/input/file and label prime/non-prime\n\n# Write your code here...\n\n\n\nSolve problem in your own work\nPlanned focus: Top words & keyword check\n\nKey topics / activities: Text cleaning, Counter, filtering by length\nExample / mini-project: From a text file, list 10 most frequent words (&gt;7 chars) and detect a target word\n\n\n# TODO: Implement: Solve problem in your own work for Day 2\n# Suggested starting hints from schedule:\n# Title: Top words & keyword check\n# Key topics / activities: Text cleaning, `Counter`, filtering by length\n# Example / Mini-project: From a text file, list 10 most frequent words (&gt;7 chars) and detect a target word\n\n# Write your code here...\n\n\n\nPerform data science using GenAI\nPlanned focus: Explore the penguins dataset\n\nKey topics / activities: Data loading from package, describe(), value_counts(), simple plots\nExample / mini-project: Load a penguins DataFrame and compute basic descriptives\n\n\n# TODO: Implement: Perform data science using GenAI for Day 2\n# Suggested starting hints from schedule:\n# Title: Explore the penguins dataset\n# Key topics / activities: Data loading from package, describe(), value_counts(), simple plots\n# Example / Mini-project: Load a penguins DataFrame and compute basic descriptives\n\n# Write your code here...",
    "crumbs": [
      "About",
      "2: Understand your dataset"
    ]
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Coding for Dummies — Workshop Program",
    "section": "",
    "text": "import pandas as pd\nfrom pathlib import Path\n\n# Adjust path if your TSV has a different name/location\ntsv_path = Path(\"schedule.tsv\")\n\n# Read TSV\ndf = pd.read_csv(tsv_path, sep=\"\\t\")\n\n# Create sortable keys\nday_order = {f\"Day {i}\": i for i in range(1, 6)}\nhour_order = {\"1\": 1, \"2\": 2, \"3\": 3}\n\ndf[\"DaySort\"] = df[\"Day\"].map(day_order)\ndf[\"HourSort\"] = df[\"Hour\"].astype(str).map(hour_order)\n\ndf = df.sort_values([\"DaySort\", \"HourSort\", \"Session Type\"]).drop(columns=[\"DaySort\",\"HourSort\"])\n\n# Render as HTML table (Quarto will display this nicely)\ndf\n\n\n\n\n\n\n\n\nDay\nModule Goal\nHour\nSession Type\nTitle\nKey Topics / Activities\nExample or Mini-Project\n\n\n\n\n0\nDay 1\nGet comfortable with Python syntax and Google ...\n1\nSimple Python Program\nTest if a string is a palindrome\nVariables, strings, conditionals, printing\nFunction that returns True/False for palindrome\n\n\n1\nDay 1\nGet comfortable with Python syntax and Google ...\n2\nSocial Science Application Idea\nCounting words in a transcript\nBrainstorm repetitive academic tasks; file I/O...\nLoad a .txt interview, count words, save a sum...\n\n\n2\nDay 1\nGet comfortable with Python syntax and Google ...\n3\nChatting with Your Data (Intro)\nSet up Colab + AI assistant\nInstall/load helpers; prompt-to-code generation\n“Make a table from survey results and sort by ...\n\n\n3\nDay 2\nLearn data structures and ingest/clean small d...\n1\nSimple Python Program\nTest if a number is prime\nLoops, modulo, early returns, simple functions\nReusable `is_prime(n)` with basic tests\n\n\n4\nDay 2\nLearn data structures and ingest/clean small d...\n2\nSocial Science Application Idea\nImport and clean a survey CSV\nRead CSV, drop duplicates, handle missing, exp...\nClean `survey.csv` → `survey_clean.csv`\n\n\n5\nDay 2\nLearn data structures and ingest/clean small d...\n3\nChatting with Your Data (Tables)\nConversational queries over tables\nUpload CSV/Excel; ask AI for cleaning & summaries\n“Top 5 categories by count” + basic describe()\n\n\n6\nDay 3\nAutomate common research data collection/prep ...\n1\nSimple Python Program\nGenerate a random password\nStrings, randomness, loops, parameterization\nPassword with letters/digits; length argument\n\n\n7\nDay 3\nAutomate common research data collection/prep ...\n2\nSocial Science Application Idea\nLightweight web scraping for text\nRequests/BeautifulSoup (guided by AI); save to...\nScrape headlines and timestamps into `news.csv`\n\n\n8\nDay 3\nAutomate common research data collection/prep ...\n3\nChatting with Your Data (Text)\nAI-assisted text analysis\nTokenization, keywords, quick sentiment\n“Most common terms in a policy document”\n\n\n9\nDay 4\nTell data stories with basic charts (Matplotli...\n1\nSimple Python Program\nCompute Fibonacci up to N\nLists, loops, function returns\nSimple sequence generator and print\n\n\n10\nDay 4\nTell data stories with basic charts (Matplotli...\n2\nSocial Science Application Idea\nPlot survey results over time\nData grouping, aggregations, export figures\nBar/line chart of response counts by month\n\n\n11\nDay 4\nTell data stories with basic charts (Matplotli...\n3\nChatting with Your Data (Graphs)\nPrompt-to-plot workflow\nCreate chart via natural language; customize l...\nAuto-generated bar chart with titles/axes save...\n\n\n12\nDay 5\nIntegrate skills into a small end-to-end project\n1\nSimple Python Program\nAverage & median from a list\nLists, built-ins, simple stats\n`mean/median` on example list + edge cases\n\n\n13\nDay 5\nIntegrate skills into a small end-to-end project\n2\nSocial Science Application Idea\nMini “data chatbot” ideation\nChoose dataset; plan load→clean→analyze→viz\nTeams sketch prompts + steps for their dataset\n\n\n14\nDay 5\nIntegrate skills into a small end-to-end project\n3\nChatting with Your Data (Showcase)\nProject demos & next steps\nRun notebooks; reflect on workflow; next resou...\nShort presentations + exported tables/plots"
  },
  {
    "objectID": "schedule.html#program-table",
    "href": "schedule.html#program-table",
    "title": "Coding for Dummies — Workshop Program",
    "section": "",
    "text": "import pandas as pd\nfrom pathlib import Path\n\n# Adjust path if your TSV has a different name/location\ntsv_path = Path(\"schedule.tsv\")\n\n# Read TSV\ndf = pd.read_csv(tsv_path, sep=\"\\t\")\n\n# Create sortable keys\nday_order = {f\"Day {i}\": i for i in range(1, 6)}\nhour_order = {\"1\": 1, \"2\": 2, \"3\": 3}\n\ndf[\"DaySort\"] = df[\"Day\"].map(day_order)\ndf[\"HourSort\"] = df[\"Hour\"].astype(str).map(hour_order)\n\ndf = df.sort_values([\"DaySort\", \"HourSort\", \"Session Type\"]).drop(columns=[\"DaySort\",\"HourSort\"])\n\n# Render as HTML table (Quarto will display this nicely)\ndf\n\n\n\n\n\n\n\n\nDay\nModule Goal\nHour\nSession Type\nTitle\nKey Topics / Activities\nExample or Mini-Project\n\n\n\n\n0\nDay 1\nGet comfortable with Python syntax and Google ...\n1\nSimple Python Program\nTest if a string is a palindrome\nVariables, strings, conditionals, printing\nFunction that returns True/False for palindrome\n\n\n1\nDay 1\nGet comfortable with Python syntax and Google ...\n2\nSocial Science Application Idea\nCounting words in a transcript\nBrainstorm repetitive academic tasks; file I/O...\nLoad a .txt interview, count words, save a sum...\n\n\n2\nDay 1\nGet comfortable with Python syntax and Google ...\n3\nChatting with Your Data (Intro)\nSet up Colab + AI assistant\nInstall/load helpers; prompt-to-code generation\n“Make a table from survey results and sort by ...\n\n\n3\nDay 2\nLearn data structures and ingest/clean small d...\n1\nSimple Python Program\nTest if a number is prime\nLoops, modulo, early returns, simple functions\nReusable `is_prime(n)` with basic tests\n\n\n4\nDay 2\nLearn data structures and ingest/clean small d...\n2\nSocial Science Application Idea\nImport and clean a survey CSV\nRead CSV, drop duplicates, handle missing, exp...\nClean `survey.csv` → `survey_clean.csv`\n\n\n5\nDay 2\nLearn data structures and ingest/clean small d...\n3\nChatting with Your Data (Tables)\nConversational queries over tables\nUpload CSV/Excel; ask AI for cleaning & summaries\n“Top 5 categories by count” + basic describe()\n\n\n6\nDay 3\nAutomate common research data collection/prep ...\n1\nSimple Python Program\nGenerate a random password\nStrings, randomness, loops, parameterization\nPassword with letters/digits; length argument\n\n\n7\nDay 3\nAutomate common research data collection/prep ...\n2\nSocial Science Application Idea\nLightweight web scraping for text\nRequests/BeautifulSoup (guided by AI); save to...\nScrape headlines and timestamps into `news.csv`\n\n\n8\nDay 3\nAutomate common research data collection/prep ...\n3\nChatting with Your Data (Text)\nAI-assisted text analysis\nTokenization, keywords, quick sentiment\n“Most common terms in a policy document”\n\n\n9\nDay 4\nTell data stories with basic charts (Matplotli...\n1\nSimple Python Program\nCompute Fibonacci up to N\nLists, loops, function returns\nSimple sequence generator and print\n\n\n10\nDay 4\nTell data stories with basic charts (Matplotli...\n2\nSocial Science Application Idea\nPlot survey results over time\nData grouping, aggregations, export figures\nBar/line chart of response counts by month\n\n\n11\nDay 4\nTell data stories with basic charts (Matplotli...\n3\nChatting with Your Data (Graphs)\nPrompt-to-plot workflow\nCreate chart via natural language; customize l...\nAuto-generated bar chart with titles/axes save...\n\n\n12\nDay 5\nIntegrate skills into a small end-to-end project\n1\nSimple Python Program\nAverage & median from a list\nLists, built-ins, simple stats\n`mean/median` on example list + edge cases\n\n\n13\nDay 5\nIntegrate skills into a small end-to-end project\n2\nSocial Science Application Idea\nMini “data chatbot” ideation\nChoose dataset; plan load→clean→analyze→viz\nTeams sketch prompts + steps for their dataset\n\n\n14\nDay 5\nIntegrate skills into a small end-to-end project\n3\nChatting with Your Data (Showcase)\nProject demos & next steps\nRun notebooks; reflect on workflow; next resou...\nShort presentations + exported tables/plots"
  },
  {
    "objectID": "schedule.html#some-info",
    "href": "schedule.html#some-info",
    "title": "Coding for Dummies — Workshop Program",
    "section": "some info",
    "text": "some info\n\nfrom IPython.display import display, Markdown, HTML\n\n# Use the already-sorted df from the previous cell\nfor day, g in df.groupby(\"Day\", sort=False):\n    display(Markdown(f\"### {day}\"))\n    # Drop the repeated Day column and render a clean sub-table\n    display(HTML(g.drop(columns=[\"Day\"]).to_html(index=False)))\n\nDay 1\n\n\n\n\n\nModule Goal\nHour\nSession Type\nTitle\nKey Topics / Activities\nExample or Mini-Project\n\n\n\n\nGet comfortable with Python syntax and Google Colab basics\n1\nSimple Python Program\nTest if a string is a palindrome\nVariables, strings, conditionals, printing\nFunction that returns True/False for palindrome\n\n\nGet comfortable with Python syntax and Google Colab basics\n2\nSocial Science Application Idea\nCounting words in a transcript\nBrainstorm repetitive academic tasks; file I/O; basic text ops\nLoad a .txt interview, count words, save a summary\n\n\nGet comfortable with Python syntax and Google Colab basics\n3\nChatting with Your Data (Intro)\nSet up Colab + AI assistant\nInstall/load helpers; prompt-to-code generation\n“Make a table from survey results and sort by age”\n\n\n\n\n\nDay 2\n\n\n\n\n\nModule Goal\nHour\nSession Type\nTitle\nKey Topics / Activities\nExample or Mini-Project\n\n\n\n\nLearn data structures and ingest/clean small datasets via low-code patterns\n1\nSimple Python Program\nTest if a number is prime\nLoops, modulo, early returns, simple functions\nReusable `is_prime(n)` with basic tests\n\n\nLearn data structures and ingest/clean small datasets via low-code patterns\n2\nSocial Science Application Idea\nImport and clean a survey CSV\nRead CSV, drop duplicates, handle missing, export clean CSV\nClean `survey.csv` → `survey_clean.csv`\n\n\nLearn data structures and ingest/clean small datasets via low-code patterns\n3\nChatting with Your Data (Tables)\nConversational queries over tables\nUpload CSV/Excel; ask AI for cleaning & summaries\n“Top 5 categories by count” + basic describe()\n\n\n\n\n\nDay 3\n\n\n\n\n\nModule Goal\nHour\nSession Type\nTitle\nKey Topics / Activities\nExample or Mini-Project\n\n\n\n\nAutomate common research data collection/prep tasks\n1\nSimple Python Program\nGenerate a random password\nStrings, randomness, loops, parameterization\nPassword with letters/digits; length argument\n\n\nAutomate common research data collection/prep tasks\n2\nSocial Science Application Idea\nLightweight web scraping for text\nRequests/BeautifulSoup (guided by AI); save to CSV\nScrape headlines and timestamps into `news.csv`\n\n\nAutomate common research data collection/prep tasks\n3\nChatting with Your Data (Text)\nAI-assisted text analysis\nTokenization, keywords, quick sentiment\n“Most common terms in a policy document”\n\n\n\n\n\nDay 4\n\n\n\n\n\nModule Goal\nHour\nSession Type\nTitle\nKey Topics / Activities\nExample or Mini-Project\n\n\n\n\nTell data stories with basic charts (Matplotlib/Plotly)\n1\nSimple Python Program\nCompute Fibonacci up to N\nLists, loops, function returns\nSimple sequence generator and print\n\n\nTell data stories with basic charts (Matplotlib/Plotly)\n2\nSocial Science Application Idea\nPlot survey results over time\nData grouping, aggregations, export figures\nBar/line chart of response counts by month\n\n\nTell data stories with basic charts (Matplotlib/Plotly)\n3\nChatting with Your Data (Graphs)\nPrompt-to-plot workflow\nCreate chart via natural language; customize labels\nAuto-generated bar chart with titles/axes saved as PNG\n\n\n\n\n\nDay 5\n\n\n\n\n\nModule Goal\nHour\nSession Type\nTitle\nKey Topics / Activities\nExample or Mini-Project\n\n\n\n\nIntegrate skills into a small end-to-end project\n1\nSimple Python Program\nAverage & median from a list\nLists, built-ins, simple stats\n`mean/median` on example list + edge cases\n\n\nIntegrate skills into a small end-to-end project\n2\nSocial Science Application Idea\nMini “data chatbot” ideation\nChoose dataset; plan load→clean→analyze→viz\nTeams sketch prompts + steps for their dataset\n\n\nIntegrate skills into a small end-to-end project\n3\nChatting with Your Data (Showcase)\nProject demos & next steps\nRun notebooks; reflect on workflow; next resources\nShort presentations + exported tables/plots"
  },
  {
    "objectID": "apws-module-5.html",
    "href": "apws-module-5.html",
    "title": "5: Seeing (data) is believing",
    "section": "",
    "text": "# Empty code cell with Python comment preceded by hash sign \"# \"\n\n\nGenerate a simple Python program\nPlanned focus: Draw a circle with NumPy and save PNG\n\nKey topics / activities: NumPy arrays as images, basic image I/O\nExample / mini-project: Create 100×100 image: green background with white circle; save as PNG\n\n\n# TODO: Implement: Generate a simple Python program for Day 5\n# Suggested starting hints from schedule:\n# Title: Draw a circle with NumPy and save PNG\n# Key topics / activities: NumPy arrays as images, basic image I/O\n# Example / Mini-project: Create 100×100 image: green background with white circle; save as PNG\n\n# Write your code here...\n\n\n\nSolve problem in your own work\nPlanned focus: Simulate an interaction & visualize\n\nKey topics / activities: Bivariate median splits, data simulation, error bars\nExample / mini-project: Generate data showing A×B interaction and plot grouped bars with error bars\n\n\n# TODO: Implement: Solve problem in your own work for Day 5\n# Suggested starting hints from schedule:\n# Title: Simulate an interaction & visualize\n# Key topics / activities: Bivariate median splits, data simulation, error bars\n# Example / Mini-project: Generate data showing A×B interaction and plot grouped bars with error bars\n\n# Write your code here...\n\n\n\nPerform data science using GenAI\nPlanned focus: Median split & cleanup on penguins (viz-ready)\n\nKey topics / activities: Recode by median, drop NAs, prep for plotting\nExample / mini-project: Recreate median-split categorical variable and export a clean, plot-ready table\n\n\n# TODO: Implement: Perform data science using GenAI for Day 5\n# Suggested starting hints from schedule:\n# Title: Median split & cleanup on penguins (viz-ready)\n# Key topics / activities: Recode by median, drop NAs, prep for plotting\n# Example / Mini-project: Recreate median-split categorical variable and export a clean, plot-ready table\n\n# Write your code here...",
    "crumbs": [
      "About",
      "5: Seeing (data) is believing"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Algorithmic prompting",
    "section": "",
    "text": "Workshop link and Schedule\nAlgorithmic prompting means giving clear, step-by-step instructions that guide AI to do useful work. In this course, you’ll learn to turn plain-language questions into prompts that create tables, charts, and quick data checks. You won’t need deep coding skills—just a method for breaking problems into small, repeatable steps. By the end, you’ll use algorithmic prompts to automate routine tasks and explore data with confidence.\nCoding for dummies workshop is for anyone with little or no programming experience who wants to use Generative AI for data analysis. In the first two sessions, you’ll get comfortable in Google Colab, learn the basics of AI-aided low-code programming, and see how a few lines of Python can automate routine tasks and streamline your workflow.\nIn the remaining sessions, we’ll dive into AI-assisted analysis with Python: “chatting with your data” in natural language to create and manipulate tables, clean and transform datasets, and build clear visualizations. By the end, you’ll know how to combine low-code Python tools with modern AI assistants to load, explore, and visualize data efficiently—producing reproducible notebooks you can adapt to your own research and reporting.\n\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "A private or organizational Google account",
    "crumbs": [
      "About",
      "Overview"
    ]
  },
  {
    "objectID": "about.html#requirements",
    "href": "about.html#requirements",
    "title": "About",
    "section": "",
    "text": "A private or organizational Google account",
    "crumbs": [
      "About",
      "Overview"
    ]
  },
  {
    "objectID": "about.html#schedule",
    "href": "about.html#schedule",
    "title": "About",
    "section": "Schedule",
    "text": "Schedule\nThe following info is fetched from timeedit:",
    "crumbs": [
      "About",
      "Overview"
    ]
  },
  {
    "objectID": "about.html#locations",
    "href": "about.html#locations",
    "title": "About",
    "section": "Locations",
    "text": "Locations\n\n\n\nworkshop locations",
    "crumbs": [
      "About",
      "Overview"
    ]
  },
  {
    "objectID": "about.html#syllabus",
    "href": "about.html#syllabus",
    "title": "About",
    "section": "Syllabus",
    "text": "Syllabus\nDownload link",
    "crumbs": [
      "About",
      "Overview"
    ]
  },
  {
    "objectID": "feedback-form.html",
    "href": "feedback-form.html",
    "title": "Feedback form",
    "section": "",
    "text": "Loading…",
    "crumbs": [
      "About",
      "Feedback form"
    ]
  },
  {
    "objectID": "prd.html",
    "href": "prd.html",
    "title": "Product Requirements Document (PRD)",
    "section": "",
    "text": "Wikipedia link",
    "crumbs": [
      "About",
      "Product Requirements Document"
    ]
  },
  {
    "objectID": "prd.html#feature-basic-stats-a-very-simple-data-science-function",
    "href": "prd.html#feature-basic-stats-a-very-simple-data-science-function",
    "title": "Product Requirements Document (PRD)",
    "section": "Feature: “Basic Stats” — a very simple data-science function",
    "text": "Feature: “Basic Stats” — a very simple data-science function\n\n1) Summary (what & why)\nBuild a tiny Python function for beginners that returns count, mean, and median for a small list of numbers. It demonstrates core skills: making a function, using built-ins, handling errors, and printing quick results.\n\n\n2) Users\n\nNovice programmers in a workshop or self-study setting using Google Colab or Python 3.\n\n\n\n3) Goals (in scope)\n\nOne function: basic_stats(values) -&gt; dict\nCompute and return: {\"count\": int, \"mean\": float, \"median\": float}\nMinimal, readable code (no external libraries)\nTiny demo that prints results\n\n\n\n4) Non-Goals (out of scope)\n\nFile I/O (CSV/Excel), plotting, pandas/NumPy\nHandling huge datasets or streaming data\n\n\n\n5) Functional Requirements\n\nAccept a list of numbers (e.g., [1, 2, 3.5]).\nIf list is empty, print a helpful message and return None.\nMean = sum(values) / len(values)\nMedian = middle value after sorting (average two middles for even length)\nReturn a dictionary with exactly three keys: count, mean, median\nProvide a tiny demo that calls the function on a few example lists and prints results.\n\n\n\n6) Non-Functional Requirements\n\nClarity over cleverness: short, commented code\nWorks on Python 3.9+\nDeterministic output; no randomness\n\n\n\n7) Success Criteria\n\nBeginners can explain what the function does and how it’s structured.\nAll acceptance tests pass without modification.\nCode fits on one screen (~20 lines excluding demo/comments).\n\n\n\n8) Acceptance Tests\n\nbasic_stats([1,2,3])  -&gt; {\"count\":3, \"mean\":2.0, \"median\":2.0}\nbasic_stats([1,2,3,4])-&gt; {\"count\":4, \"mean\":2.5, \"median\":2.5}\nbasic_stats([5])      -&gt; {\"count\":1, \"mean\":5.0, \"median\":5.0}\nbasic_stats([])       -&gt; prints \"No values provided.\" and returns None\n\n\n\n9) Error/Edge Handling\n\nEmpty input: graceful message + None\nNon-numeric items: (for this minimal version) assume numeric; instructor may extend later\n\n\n\n10) Deliverables\n\nOne Python cell or basic_stats.py containing the function + demo\n\n\n\n11) Reference Implementation (minimal)\ndef basic_stats(values):\n    if not values:\n        print(\"No values provided.\")\n        return None\n    vals = list(values)             # ensure indexable\n    n = len(vals)\n    mean = sum(vals) / n\n    s = sorted(vals)\n    mid = n // 2\n    median = s[mid] if n % 2 else (s[mid-1] + s[mid]) / 2\n    return {\"count\": n, \"mean\": float(mean), \"median\": float(median)}\n\n# Demo\nfor ex in ([1,2,3], [1,2,3,4], [5], []):\n    print(ex, \"-&gt;\", basic_stats(ex))\n\n\n12) Extension Ideas (later, optional)\n\nSkip or coerce non-numeric values with friendly messages\nAdd min/max; round to N decimals; unit tests",
    "crumbs": [
      "About",
      "Product Requirements Document"
    ]
  },
  {
    "objectID": "modules.html",
    "href": "modules.html",
    "title": "Modules",
    "section": "",
    "text": "Each day of the workshop we will work on a module, and each module consists of the same three elements:\nFor each day of the workshop, we will undertake our programming work and store the results in separate Google Colab notebooks.",
    "crumbs": [
      "About",
      "Modules"
    ]
  },
  {
    "objectID": "modules.html#program-table",
    "href": "modules.html#program-table",
    "title": "Modules",
    "section": "Program Table",
    "text": "Program Table\n\n\nDay 1\n\n\n\n\n\nModule Goal\nHour\nSession Type\nTitle\nKey Topics / Activities\nExample or Mini-Project\n\n\n\n\nModule 1: All programs need data?\n1\nGenerate a simple Python program\nLine-by-line palindrome checker\nStrings, slicing, input/file I/O, stepwise refinement (hardcoded → input() → file)\nRead a text file and print whether each line is a palindrome\n\n\nModule 1: All programs need data?\n2\nSolve problem in your own work\nPersonalized emails from TSV\nFile I/O (TSV), f-strings/templates, loops\nRead a name list TSV and generate short personalized mail messages\n\n\nModule 1: All programs need data?\n3\nPerform data science using GenAI\nLoad real-world data into pandas\nPandas `read_csv`/`read_table`/`read_excel`, parsing unstructured text\nLoad Excel/TSV/text into a single DataFrame and preview/clean columns\n\n\n\n\n\nDay 2\n\n\n\n\n\nModule Goal\nHour\nSession Type\nTitle\nKey Topics / Activities\nExample or Mini-Project\n\n\n\n\nModule 2: Understand your dataset\n1\nGenerate a simple Python program\nLine-by-line prime number tester\nLoops, modulo, input/file I/O, simple edge cases\nTest numbers from hardcoded/input/file and label prime/non-prime\n\n\nModule 2: Understand your dataset\n2\nSolve problem in your own work\nTop words & keyword check\nText cleaning, `Counter`, filtering by length\nFrom a text file, list 10 most frequent words (&gt;7 chars) and detect a target word\n\n\nModule 2: Understand your dataset\n3\nPerform data science using GenAI\nExplore the penguins dataset\nData loading from package, describe(), value_counts(), simple plots\nLoad a penguins DataFrame and compute basic descriptives\n\n\n\n\n\nDay 3\n\n\n\n\n\nModule Goal\nHour\nSession Type\nTitle\nKey Topics / Activities\nExample or Mini-Project\n\n\n\n\nModule 3: Data transformations!!\n1\nGenerate a simple Python program\nNormalize a list to 0–1 and compare\nMin–max scaling, lists → DataFrame, two-column output\nCreate a two-column DataFrame: original vs normalized values\n\n\nModule 3: Data transformations!!\n2\nSolve problem in your own work\nAnonymize & categorize respondents\nRegex for names, age binning into 3 groups\nRead TSV (first,last,age,preference), anonymize IDs, add 3 age categories\n\n\nModule 3: Data transformations!!\n3\nPerform data science using GenAI\nMedian split & missing-value handling on penguins\nRecode numeric → categorical (median), drop NAs\nRecode a numeric variable by median split; remove missing values\n\n\n\n\n\nDay 4\n\n\n\n\n\nModule Goal\nHour\nSession Type\nTitle\nKey Topics / Activities\nExample or Mini-Project\n\n\n\n\nModule 4: Humans need data summary\n1\nGenerate a simple Python program\nDate differences with holidays & weeks\n`datetime` arithmetic, Swedish holidays count, full-weeks calc\nInput two dates; output days between, #Swedish holidays, #full weeks\n\n\nModule 4: Humans need data summary\n2\nSolve problem in your own work\nGroup summaries with SEM\nGroupby aggregations: count, mean, std, SEM\nFrom TSV with 3-level categorical + numeric, compute grouped stats (count/mean/std/SEM)\n\n\nModule 4: Humans need data summary\n3\nPerform data science using GenAI\nSummary table by factor on penguins\nGroupby on categorical IV, numeric DV; formatted table\nAggregate a numeric DV by a categorical IV and render a neat summary table\n\n\n\n\n\nDay 5\n\n\n\n\n\nModule Goal\nHour\nSession Type\nTitle\nKey Topics / Activities\nExample or Mini-Project\n\n\n\n\nModule 5: Seeing (data) is believing\n1\nGenerate a simple Python program\nDraw a circle with NumPy and save PNG\nNumPy arrays as images, basic image I/O\nCreate 100×100 image: green background with white circle; save as PNG\n\n\nModule 5: Seeing (data) is believing\n2\nSolve problem in your own work\nSimulate an interaction & visualize\nBivariate median splits, data simulation, error bars\nGenerate data showing A×B interaction and plot grouped bars with error bars\n\n\nModule 5: Seeing (data) is believing\n3\nPerform data science using GenAI\nMedian split & cleanup on penguins (viz-ready)\nRecode by median, drop NAs, prep for plotting\nRecreate median-split categorical variable and export a clean, plot-ready table",
    "crumbs": [
      "About",
      "Modules"
    ]
  }
]